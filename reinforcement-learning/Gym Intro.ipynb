{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![model](https://miro.medium.com/max/960/1*tGwmW_pXT-Inqarion6lWg.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " action [-0.0548751] \n",
      " observation [-5.87277704e-01  3.95290059e-04] \n",
      " reward -0.0003011276399040919 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.84813374] \n",
      " observation [-5.87679922e-01 -4.02218256e-04] \n",
      " reward -0.07193308456917046 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.45337987] \n",
      " observation [-0.58828456 -0.00060463] \n",
      " reward -0.020555330603252743 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.1171715] \n",
      " observation [-5.88582844e-01 -2.98287464e-04] \n",
      " reward -0.0013729161256695267 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.4737677] \n",
      " observation [-5.89107484e-01 -5.24639899e-04] \n",
      " reward -0.02244558314892551 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.530896] \n",
      " observation [-0.58994031 -0.00083283] \n",
      " reward -0.028185057132592208 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.47227463] \n",
      " observation [-5.89570439e-01  3.69870006e-04] \n",
      " reward -0.022304332733349332 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.0421051] \n",
      " observation [-0.58877216  0.00079828] \n",
      " reward -0.00017728398480494484 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.6004344] \n",
      " observation [-5.88388846e-01  3.83316373e-04] \n",
      " reward -0.03605214957144796 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.7676764] \n",
      " observation [-5.88674173e-01 -2.85326635e-04] \n",
      " reward -0.05893270751674926 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.60249627] \n",
      " observation [-0.58757078  0.00110339] \n",
      " reward -0.03630017509838268 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.6312414] \n",
      " observation [-0.58693741  0.00063338] \n",
      " reward -0.03984656812993457 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.7623908] \n",
      " observation [-5.86975430e-01 -3.80229176e-05] \n",
      " reward -0.058123972029031634 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.5317736] \n",
      " observation [-0.58574333  0.0012321 ] \n",
      " reward -0.028278319016465405 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.323793] \n",
      " observation [-0.58356214  0.00218118] \n",
      " reward -0.010484190297797014 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.9454326] \n",
      " observation [-0.57951551  0.00404663] \n",
      " reward -0.08938428074945969 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.9094455] \n",
      " observation [-0.57641563  0.00309988] \n",
      " reward -0.08270911615159662 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.65647304] \n",
      " observation [-0.57193657  0.00447906] \n",
      " reward -0.04309568530093344 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.6922555] \n",
      " observation [-0.56813463  0.00380194] \n",
      " reward -0.04792176730973097 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.03182403] \n",
      " observation [-0.5640474   0.00408723] \n",
      " reward -0.00010127691214084773 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.86223966] \n",
      " observation [-0.5583642   0.00568321] \n",
      " reward -0.07434572292636724 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.39011464] \n",
      " observation [-0.55183555  0.00652865] \n",
      " reward -0.015218942861994211 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.47280997] \n",
      " observation [-0.54438616  0.00744939] \n",
      " reward -0.022354926808967335 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.18577574] \n",
      " observation [-0.5365023   0.00788386] \n",
      " reward -0.0034512626291416607 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.4506156] \n",
      " observation [-0.52784577  0.00865653] \n",
      " reward -0.020305443216877085 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.22188497] \n",
      " observation [-0.51882456  0.00902121] \n",
      " reward -0.004923293809093821 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.05956252] \n",
      " observation [-0.50974981  0.00907475] \n",
      " reward -0.0003547694136355598 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.5234266] \n",
      " observation [-0.50156404  0.00818577] \n",
      " reward -0.02739753975791395 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.33733147] \n",
      " observation [-0.49303741  0.00852663] \n",
      " reward -0.011379252323454027 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.5706132] \n",
      " observation [-0.4855956   0.00744182] \n",
      " reward -0.03255994302143996 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.76508725] \n",
      " observation [-0.47958581  0.00600978] \n",
      " reward -0.058535849536112045 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.7099904] \n",
      " observation [-0.47284019  0.00674563] \n",
      " reward -0.050408634280871924 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.01050381] \n",
      " observation [-0.46648953  0.00635065] \n",
      " reward -1.1033012022063169e-05 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.17208587] \n",
      " observation [-0.46082324  0.0056663 ] \n",
      " reward -0.0029613545391253605 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.17455441] \n",
      " observation [-0.45536315  0.00546009] \n",
      " reward -0.0030469241211395826 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.8772742] \n",
      " observation [-0.45172717  0.00363598] \n",
      " reward -0.07696100486923321 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.31614488] \n",
      " observation [-0.44815184  0.00357533] \n",
      " reward -0.009994758744710808 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.7046766] \n",
      " observation [-0.44619457  0.00195728] \n",
      " reward -0.049656915020841554 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.33409685] \n",
      " observation [-0.44531376  0.0008808 ] \n",
      " reward -0.011162070448813566 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.5346502] \n",
      " observation [-0.44421274  0.00110102] \n",
      " reward -0.02858508433809135 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.91136414] \n",
      " observation [-0.44233445  0.00187829] \n",
      " reward -0.08305845922628273 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.7034816] \n",
      " observation [-0.4400044   0.00233005] \n",
      " reward -0.04948863820657188 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.32288063] \n",
      " observation [-0.43877908  0.00122532] \n",
      " reward -0.010425189846843354 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.3550996] \n",
      " observation [-4.38715717e-01  6.33653332e-05] \n",
      " reward -0.012609571784703011 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.93550134] \n",
      " observation [-0.43787886  0.00083685] \n",
      " reward -0.08751627516249415 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.3885539] \n",
      " observation [-0.43709502  0.00078385] \n",
      " reward -0.01509741235734774 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.13155513] \n",
      " observation [-4.36755360e-01  3.39658749e-04] \n",
      " reward -0.0017306750944628968 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.6259934] \n",
      " observation [-0.43612069  0.00063467] \n",
      " reward -0.039186770054824654 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.40290394] \n",
      " observation [-0.43673896 -0.00061827] \n",
      " reward -0.01623315882953671 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.6919512] \n",
      " observation [-4.36963408e-01 -2.24444372e-04] \n",
      " reward -0.04787964843097292 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.6248027] \n",
      " observation [-4.36893122e-01  7.02851641e-05] \n",
      " reward -0.039037842470612816 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.54817253] \n",
      " observation [-4.36643562e-01  2.49560017e-04] \n",
      " reward -0.03004931264970914 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.8610328] \n",
      " observation [-0.43833034 -0.00168678] \n",
      " reward -0.07413774550971973 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.6465842] \n",
      " observation [-0.43967981 -0.00134947] \n",
      " reward -0.041807114421633075 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.7804722] \n",
      " observation [-0.44282275 -0.00314294] \n",
      " reward -0.06091368846156833 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.7459869] \n",
      " observation [-0.44544662 -0.00262387] \n",
      " reward -0.055649642344906526 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.70219195] \n",
      " observation [-0.44759798 -0.00215137] \n",
      " reward -0.04930735330868999 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.36281532] \n",
      " observation [-0.45085865 -0.00326067] \n",
      " reward -0.013163495678356086 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.17341052] \n",
      " observation [-0.45492067 -0.00406202] \n",
      " reward -0.003007120843194522 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.4504785] \n",
      " observation [-0.45881842 -0.00389775] \n",
      " reward -0.020293087370726326 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.2339308] \n",
      " observation [-0.46284807 -0.00402965] \n",
      " reward -0.005472361749723209 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.9132932] \n",
      " observation [-0.46596089 -0.00311282] \n",
      " reward -0.08341044378400718 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.3574244] \n",
      " observation [-0.47003999 -0.00407909] \n",
      " reward -0.012775220757526374 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.44003466] \n",
      " observation [-0.47385899 -0.00381901] \n",
      " reward -0.019363049999189832 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.4302765] \n",
      " observation [-0.47740425 -0.00354526] \n",
      " reward -0.018513787772521086 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.4509181] \n",
      " observation [-0.48197123 -0.00456699] \n",
      " reward -0.020332714032509448 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.7591442] \n",
      " observation [-0.4857109  -0.00373966] \n",
      " reward -0.057629989661576536 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.64559335] \n",
      " observation [-0.4907025 -0.0049916] \n",
      " reward -0.041679076732166115 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.52273905] \n",
      " observation [-0.49515632 -0.00445382] \n",
      " reward -0.027325611729351353 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.8128833] \n",
      " observation [-0.50104252 -0.0058862 ] \n",
      " reward -0.06607792878219279 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.48854196] \n",
      " observation [-0.50636495 -0.00532243] \n",
      " reward -0.02386732473804756 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.55304486] \n",
      " observation [-0.51264614 -0.00628119] \n",
      " reward -0.03058586122996907 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.19059704] \n",
      " observation [-0.51929536 -0.00664922] \n",
      " reward -0.0036327232587396677 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.02479941] \n",
      " observation [-0.52601405 -0.00671869] \n",
      " reward -6.150107489344554e-05 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.20424858] \n",
      " observation [-0.533021   -0.00700695] \n",
      " reward -0.004171748135208819 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.8058657] \n",
      " observation [-0.5411661  -0.00814509] \n",
      " reward -0.06494195345165431 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.523251] \n",
      " observation [-0.54996437 -0.00879828] \n",
      " reward -0.02737916059310841 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.58412284] \n",
      " observation [-0.5594413  -0.00947692] \n",
      " reward -0.034119948822572965 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.7466164] \n",
      " observation [-0.56976984 -0.01032855] \n",
      " reward -0.055743608328748806 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.09738769] \n",
      " observation [-0.57960713 -0.00983729] \n",
      " reward -0.0009484362908042387 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.30696902] \n",
      " observation [-0.58948678 -0.00987965] \n",
      " reward -0.009422997726925876 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.875319] \n",
      " observation [-0.59756251 -0.00807573] \n",
      " reward -0.07661833588665559 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.56207365] \n",
      " observation [-0.60424494 -0.00668243] \n",
      " reward -0.031592678574896026 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.5721556] \n",
      " observation [-0.60947017 -0.00522523] \n",
      " reward -0.03273620246904017 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.63224715] \n",
      " observation [-0.6131101  -0.00363993] \n",
      " reward -0.039973645861269703 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.00904746] \n",
      " observation [-0.6161003 -0.0029902] \n",
      " reward -8.18566132922147e-06 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.5867918] \n",
      " observation [-0.6192858 -0.0031855] \n",
      " reward -0.034432463224223754 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.1708635] \n",
      " observation [-0.62150717 -0.00222137] \n",
      " reward -0.0029194333676546558 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.34012476] \n",
      " observation [-0.62351492 -0.00200775] \n",
      " reward -0.011568484971058357 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.90774137] \n",
      " observation [-6.23422861e-01  9.20580477e-05] \n",
      " reward -0.08239943908461421 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.9820266] \n",
      " observation [-0.6240663  -0.00064344] \n",
      " reward -0.09643761979261854 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.29603758] \n",
      " observation [-6.23523539e-01  5.42764177e-04] \n",
      " reward -0.008763825146218896 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.50181556] \n",
      " observation [-6.22995237e-01  5.28302266e-04] \n",
      " reward -0.025181885372882108 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.74867004] \n",
      " observation [-6.22855465e-01  1.39772141e-04] \n",
      " reward -0.056050683113113925 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.844659] \n",
      " observation [-0.62071523  0.00214023] \n",
      " reward -0.07134487770083667 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.2847468] \n",
      " observation [-0.61742976  0.00328547] \n",
      " reward -0.008108073777116776 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.137159] \n",
      " observation [-0.61324408  0.00418568] \n",
      " reward -0.001881259259977619 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [0.70044917] \n",
      " observation [-0.60734347  0.00590062] \n",
      " reward -0.049062903790744274 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.33147797] \n",
      " observation [-0.60131857  0.0060249 ] \n",
      " reward -0.01098776445189964 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n",
      " action [-0.13948816] \n",
      " observation [-0.59492527  0.0063933 ] \n",
      " reward -0.0019456946950416666 \n",
      " done False \n",
      " info \n",
      " \n",
      " {}\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/openai/gym/wiki/MountainCarContinuous-v0\n",
    "# https://towardsdatascience.com/reinforcement-learning-with-openai-d445c2c687d2\n",
    "\n",
    "import gym\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "\n",
    "observation = env.reset()\n",
    "for t in range(100):\n",
    "        env.render()\n",
    "\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        print (\" action\", action, \"\\n observation\", observation, \"\\n reward\", reward, \"\\n done\", done, \"\\n info \\n \\n\", info)\n",
    "        \n",
    "        if done:\n",
    "            print(\"Finished after {} timesteps\".format(t+1))\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
